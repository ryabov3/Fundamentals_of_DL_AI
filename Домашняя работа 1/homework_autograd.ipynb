{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9cec8e4-d60c-4a22-80b7-d81f9d83d10e",
   "metadata": {},
   "source": [
    "# Задание 2: Автоматическое дифференцирование."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2248d165-54eb-4c0d-a60a-6ce7a1ed3969",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2.0. Импорт библиотеки и создание девайса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5315b8dd-01d5-4227-9ec6-1f8b0a6b1128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тензоры на cuda:0.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Введём устройство, на котором будут работать тензоры.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Тензоры на {device}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3881f6e6-9a55-4645-bd19-7774f11ce69d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2.1. Простые вычисления с градиентами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7924912-eab3-45e0-9438-ef2a750012ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Автоматический x.grad: tensor([32., 52.])\n",
      "Автоматический y.grad: tensor([16., 32.])\n",
      "Автоматический z.grad: tensor([16., 28.])\n",
      "\n",
      "Аналитический x.grad: tensor([32., 52.], grad_fn=<AddBackward0>)\n",
      "Аналитический y.grad: tensor([16., 32.], grad_fn=<AddBackward0>)\n",
      "Аналитический z.grad: tensor([16., 28.], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1., 2.], requires_grad=True)\n",
    "y = torch.tensor([3., 4.], requires_grad=True)\n",
    "z = torch.tensor([5., 6.], requires_grad=True)\n",
    "\n",
    "def find_gradients(x, y, z):\n",
    "    \"\"\"\n",
    "    Аналитически вычисляет градиенты для тензоров x, y, z\n",
    "    \"\"\"\n",
    "    grad_x = 2 * x + 2 * y * z\n",
    "    grad_y = 2 * y + 2 * x * z\n",
    "    grad_z = 2 * z + 2 * y * x\n",
    "\n",
    "    return grad_x, grad_y, grad_z\n",
    "\n",
    "f = lambda x, y, z: (x**2 + y**2 + z**2 + 2 * x * y * z).sum()\n",
    "f(x, y, z).backward()\n",
    "\n",
    "grad_x_analytic, grad_y_analytic, grad_z_analytic = find_gradients(x, y, z)\n",
    "\n",
    "print(f\"Автоматический x.grad: {x.grad}\")\n",
    "print(f\"Автоматический y.grad: {y.grad}\")\n",
    "print(f\"Автоматический z.grad: {z.grad}\\n\")\n",
    "\n",
    "print(f\"Аналитический x.grad: {grad_x_analytic}\")\n",
    "print(f\"Аналитический y.grad: {grad_y_analytic}\")\n",
    "print(f\"Аналитический z.grad: {grad_z_analytic}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c06c28-ef2f-4674-8e21-a089e190514e",
   "metadata": {},
   "source": [
    "## 2.2. Градиент функции потерь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7fb8f91-098b-41c6-8855-89adc184cdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y_true, y_pred):\n",
    "    return torch.mean((y_pred - y_true) ** 2)\n",
    "\n",
    "def find_gradients(X, y_true, w, b):\n",
    "    \"\"\"\n",
    "    Аналитически вычисляет градиенты MSE по w и b.\n",
    "    \"\"\"\n",
    "    n = len(y_true)\n",
    "    y_pred = w * X + b\n",
    "    \n",
    "    grad_w = -(2 / n) * X.T @ (y_true - y_pred)\n",
    "    grad_b = -(2 / n) * (y_true - y_pred)\n",
    "    \n",
    "    return grad_w, grad_b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75691171-51f4-412f-927d-c0d5618dd08d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2.3. Цепное правило"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "798e2f7a-6da5-4790-ba07-ed04161f4fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: tensor([1., 2., 3.], requires_grad=True)\n",
      "\n",
      "Аналитический градиент: tensor([-0.8323,  1.1346, -5.0344], grad_fn=<MulBackward0>)\n",
      "Автоматический градиент: tensor([-0.8323,  1.1346, -5.0344], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def func(x): \n",
    "    return torch.sin(x**2 + 1)\n",
    "\n",
    "def find_gradients(x):\n",
    "    \"\"\"\n",
    "    Аналитически вычисляет градиенты с помощью производной функции func.\n",
    "    \"\"\"\n",
    "    return torch.cos(x**2 + 1) * 2 * x\n",
    "\n",
    "x = torch.tensor([1., 2., 3.], requires_grad=True)\n",
    "res = func(x)\n",
    "\n",
    "grad_analytics = find_gradients(x)\n",
    "\n",
    "grad_auto = torch.autograd.grad(\n",
    "    outputs=res, \n",
    "    inputs=x,\n",
    "    grad_outputs=torch.ones_like(res),\n",
    "    create_graph=True\n",
    ")[0]\n",
    "\n",
    "print(f\"X: {x}\\n\")\n",
    "print(f\"Аналитический градиент: {grad_analytics}\")\n",
    "print(f\"Автоматический градиент: {grad_auto}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf16e9f-af1d-4b97-99a6-51c092cc93a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

# Задание 3: Кастомные слои и эксперименты
## 3.1. Реализация кастомных слоев

#### 1. Создал необходимые кастомные слои.
* Кастомный сверточный слой имеет дополнительную логику в виде масштабирования и сдвигов по каналам.
* Attention-механизм, который селективно усиливает важные пространственныее и канальные признаки в изображении.
* Кастомная функции активации Swish, которая должна обеспечивать более гибкое и эффективное обучение сложных архитектурах.
* Кастомный пулинговый слой, который реализует пулинг на основе Lp-нормы, где p определяет тип нормы (p=2 для Евклидовой нормы, p=1 для манхэттенской), использует заданные kernel_size и stride для разделения входного тензора на окна.

#### 2. Сравнение со стандартными аналогами (тут же было forward и backward).

- Сравнение кастомного сверточного слоя со стандартными:

![image](https://github.com/user-attachments/assets/07f64b6a-9003-471e-aed9-2dbff33230b2)

- Сравнение кастомной функции потерь со стандартными relu и sigmoid.

![image](https://github.com/ryabov3/Fundamentals_of_DL_AI/blob/main/%D0%94%D0%BE%D0%BC%D0%B0%D1%88%D0%BD%D1%8F%D1%8F%20%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D0%B0%204/plots/swish_task_3_1.jpg)

- Сравнение кастомного пулинга с MaxPool и AvgPool.

![image](https://github.com/user-attachments/assets/21e19c17-d8b4-4635-8623-3b8fb2a6f463)

## 3.2. Эксперименты с Residual блоками

#### 1. Создание необоходимых Residual блоков.
#### 2. Создание модели DiffBlocksNN, которая принимает различные виды слоёв.
#### 3. Создание функции визуализации различных параметров.
#### 4. Обучение модели с разными блоками.
#### 4. Таблица сравнение производительности Residual блоков:

![image](https://github.com/user-attachments/assets/2c10c4ec-3252-4d51-ad21-7018812220af)

**Выводы по таблице:**
1. **Точность (Final Accuracy)**
- **Wide**: Лучшая точность (78.94%), но всего на 0.2% лучше basic
- **Basic**: Близкая к wide точность (78.75%)
- **Bottleneck**: Заметно хуже (74.24%) - проигрыш ~4.5%

2. **Ресурсоёмкость**
- **Параметры**:
  - Bottleneck в 12.7x экономнее basic и в 50.7x экономнее wide
- **Память**:
  - Bottleneck использует на 25% меньше памяти, чем basic
  - Wide требует в 3x больше памяти, чем basic
- **Скорость**:
  - Bottleneck обучается на 31% быстрее basic
  - Wide в 3x медленнее basic

3. **Эффективность**
- **На параметры**:
  - Bottleneck в 11.9x эффективнее basic
- **На время обучения**:
  - Bottleneck достигает точности на 37% быстрее basic
- **На память**:
  - Bottleneck на 25% эффективнее basic по использованию памяти






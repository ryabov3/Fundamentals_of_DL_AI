# Задание 1: Стандартные аугментации torchvision
#### 1. Создание конфигурации с аугментациями.

1. Создаём словарь, в котором будут содержаться все аугментации отдельно и вместе с одном пайпалане. Создаём ключ со значением без аугментаций для оригинального изображения.
2. Следом рандомно извлекаем по одному изображению из каждого из 5 рандомных классов с помощью np.random.choice.
3. В цикле проходимся по каждому изображению и применяем к нему последовательно аугментации из конфигурации.
4. Помещаем изменённые изображения на plot.

- **Все изображения и применные к ним аугментации:**

![image](https://github.com/ryabov3/Fundamentals_of_DL_AI/blob/main/%D0%94%D0%BE%D0%BC%D0%B0%D1%88%D0%BD%D1%8F%D1%8F%20%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D0%B0%205/results/augmentations_visualization.jpg)

# Задание 2: Кастомные аугментации
#### 1. Создаём три кастомные аугментации. 

**1.1. Случайное размытие изображения**:
  1. С вероятностью `p` решает, применять ли размытие
  2. Если применяется:
     - Выбирает случайный радиус размытия от 0.1 до `max_radius`
     - Обрабатывает изображение в зависимости от его типа:
        - Для `torch.Tensor`: конвертирует в PIL, применяет размытие, конвертирует обратно
        - Для PIL.Image: применяет размытие напрямую
  3. Если размытие не применяется - возвращает исходное изображение

**1.2. Случайное размытие движения**:
1. С вероятностью `p` решает применять эффект;
2. Если применяется:
    - Конвертирует PIL.Image в тензор при необходимости
    - Генерирует случайное ядро размытия:
       - Выбирает случайный нечетный размер ядра;
       - Выбирает случайный угол направления;
    - Применяет свертку с ядром размытия;
    - Конвертирует обратно в PIL при необходимости.
  
**1.3. Случайное изменение яркости**:
   - С вероятностью `p` применяет преобразования:
     - `brightness_factor`: случайное значение из диапазона `brightness_range`
     - `contrast_factor`: случайное значение из диапазона `contrast_range`
   - Иначе возвращает исходное изображение без изменений.     

#### 2. Импортируем готовые аугментации из extra_augs.py.
#### 3. Применение аугментаций:
1. Создаём словари для кастомных аугментаций и extra_augs-аугментаций.
2. Выбираем 3 рандомных изображения с помощью np.random.choice.
3. Для каждого изображения по отдельности применяем аугментации.
4. Визуализируем результат.

#### 4. Визуализация результата аугментаций:
![image](https://github.com/ryabov3/Fundamentals_of_DL_AI/blob/main/%D0%94%D0%BE%D0%BC%D0%B0%D1%88%D0%BD%D1%8F%D1%8F%20%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D0%B0%205/results/custom_vs_extra_augmentations.jpg)

# Задание 3: Анализ датасета
#### 1. Подсчёт количества изображений:
1. Проходимся по всем папкам всех классов, в словарь, где ключ - имя класса, записываем количество всех классов.
2. Параллельно вычисляем размер изображения.
3. В словарь с размерами изображений к каждому классу добавляем размеры изображения (ширину и высоту).
4. Конвертируем список со всеми изображениями в numpy.

#### 2. Список со статистикой.
2.1. Создаём список, в котором вычисляем:
  - Минимальную ширину изображений;
  - Максимальную ширину изображений;
  - Среднюю ширину всех изображений;
  - Минимальную высоту изображений;
  - Максимальную высоту изображений;
  - Среднюю высоту изображений.

#### 3. Визуализация размеров и количества изображений.
1. Создаём графики с распределением изображений по классам и размерам:
![image](https://github.com/ryabov3/Fundamentals_of_DL_AI/blob/main/%D0%94%D0%BE%D0%BC%D0%B0%D1%88%D0%BD%D1%8F%D1%8F%20%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D0%B0%205/results/dataset_analysis.jpg)

**Выводы:**
* Исходя из графика можно сделать, что в датасете идеальное соотношение количества изображений по классам: в каждом классе по 30 изображений;
* Что средняя ширина и высота изображения больше 500x600.

# Задание 4: Pipeline аугментаций
### 1. Реализация класса AugmentationPipeline.
1. При инициализации класса создаётся словарь с аугментациями.
2. В метод `add_augmentation()` передаётся название аугментации и сама аугментация. После этого она помещается в словарь.
3. В метод `remove_augmentation()` передаётся название аугментации. После чего она удаляется из словаря.
4. Метод `get_augmentations()` возвращает словарь с аугментациями.
5. Методу `apply()` передаётся изображение и он применяет все ранее созданные аугментации к нему.

#### 2. Создание конфигураций light, medium, heavy.
1. Метод `get_light_augmentations()` создаёт аугментации флип + цвет.
2. Метод `get_medium_augmentations()` создаёт аугментации флип, цвет, поворот и кроп.
3. Метод `get_heavy_augmentations()` создаёт аугментации из medium + grayscale и blur.

Данные методы возвращают созданные пайплайн.

#### 3. Функция для применения пайплайна к каждому изображению.
1. Создаём функцию `apply_and_save_augmentations()`, которая применяет аугментации к датасету и сохраняет результаты.
2. Данная функция проходится по всем 180 изображениям в датасете, применяя к ним определённую конфигурацию и сохраняет новый train_dataset в указанную папку.

***Ссылка на новый датасет:*** https://drive.google.com/drive/folders/14KfwQnJoj62te2IXI80crrgqzbQhJXtJ

# Задание 5: Эксперимент с размерами
#### 1. Обновление класса датасета.
1. Создал новый класс датасета, наследованный от старого, который имеет новый метод `set_target_size()`, который устанавливает новый размер изображений.

#### 2. Класс для пайплайна аугментаций.
1. Удалил лишние методы для данной задачи из класса AugmentationPipeline, оставив только методы `apply()` и `add_augmentation()` (убрал параметр name).

#### 3. Функции для измерения памяти, создания пайплайна и запуска эксперемента.
1. Создал функцию `create_standard_pipeline()`, которая создаёт пайплайн из аугментаций флипа, цвета, ротации и кропа.
2. Создал функцию `get_memory_usage()` для измерения потребления памяти в МБ.
3. Ну и создал функцию для запуска эксперимента для одного размера изображения `run_size_experiment()`, которая принимает датасет, пайплайн и количество изображений:
  - Применяет аугментации к изоражениям разного размера.
  - Вычисляет и сохраняет время загрузки, время применяния аугментаций, память самих данных и общее потребление памяти.

**Результаты**:

![image](https://github.com/user-attachments/assets/d3a1df3c-83c6-46f7-933a-3bfbf67335d0)

**Графики**:

![Image alt](https://github.com/ryabov3/Fundamentals_of_DL_AI/blob/main/%D0%94%D0%BE%D0%BC%D0%B0%D1%88%D0%BD%D1%8F%D1%8F%20%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D0%B0%205/results/size_experiment_results_custom_task5.png)

Как и ожидалось, меньше всего время загрузки и общее потребление памяти у изображений 64х64, а наибольшее у 512х512.
